# Model Catalog for MultiAgent CLI
# This file contains the static model definitions used as fallback
# when dynamic fetching is not available

version: "1.0"
schema: "model-catalog-v1"
generated: "2024-01-01T00:00:00Z"
last_updated: "2024-01-01T00:00:00Z"

providers:
  - provider:
      name: "anthropic"
      base_url: "https://api.anthropic.com/v1"
      auth_method: "api_key"
      models_endpoint: "/models"
      supports_list: false
      requires_auth: true
      rate_limit_rps: 50
      default_headers:
        anthropic-version: "2023-06-01"
    
    models:
      - id: "claude-3-5-sonnet-20241022"
        provider: "anthropic"
        name: "Claude 3.5 Sonnet"
        description: "Balanced intelligence and speed with strong reasoning"
        max_tokens: 8192
        input_price_per_1m: 3.0
        output_price_per_1m: 15.0
        pricing_tier: "standard"
        capabilities:
          - "chat"
          - "vision"
          - "code"
          - "reasoning"
        status: "available"
        context_window: 200000
        training_cutoff: "2024-04"
        supports_vision: true
        supports_tool_use: true
        recommended_for:
          - "coding"
          - "analysis"
          - "reasoning"
          - "general"
        aliases:
          - "claude-sonnet"
          - "sonnet"

      - id: "claude-3-5-haiku-20241022"
        provider: "anthropic"
        name: "Claude 3.5 Haiku"
        description: "Fast and cost-effective for lightweight actions"
        max_tokens: 4096
        input_price_per_1m: 1.0
        output_price_per_1m: 5.0
        pricing_tier: "budget"
        capabilities:
          - "chat"
          - "vision"
        status: "available"
        context_window: 200000
        training_cutoff: "2024-07"
        supports_vision: true
        supports_tool_use: true
        recommended_for:
          - "quick"
          - "chat"
          - "simple"
        aliases:
          - "claude-haiku"
          - "haiku"

      - id: "claude-3-opus-20240229"
        provider: "anthropic"
        name: "Claude 3 Opus"
        description: "Most capable model for complex tasks"
        max_tokens: 4096
        input_price_per_1m: 15.0
        output_price_per_1m: 75.0
        pricing_tier: "premium"
        capabilities:
          - "chat"
          - "vision"
          - "code"
          - "reasoning"
        status: "available"
        context_window: 200000
        training_cutoff: "2024-02"
        supports_vision: true
        supports_tool_use: true
        recommended_for:
          - "complex"
          - "analysis"
          - "coding"
          - "research"
        aliases:
          - "claude-opus"
          - "opus"

  - provider:
      name: "openai"
      base_url: "https://api.openai.com/v1"
      auth_method: "bearer"
      models_endpoint: "/models"
      supports_list: true
      requires_auth: true
      rate_limit_rps: 100
    
    models:
      - id: "gpt-4o"
        provider: "openai"
        name: "GPT-4o"
        description: "Most capable multimodal model, flagship GPT-4 model"
        max_tokens: 4096
        input_price_per_1m: 2.5
        output_price_per_1m: 10.0
        pricing_tier: "standard"
        capabilities:
          - "chat"
          - "vision"
          - "code"
          - "function_calling"
        status: "available"
        context_window: 128000
        training_cutoff: "2023-10"
        supports_vision: true
        supports_tool_use: true
        recommended_for:
          - "general"
          - "vision"
          - "multimodal"
        aliases:
          - "gpt4o"

      - id: "gpt-4o-mini"
        provider: "openai"
        name: "GPT-4o Mini"
        description: "Affordable and intelligent small model for fast tasks"
        max_tokens: 16384
        input_price_per_1m: 0.15
        output_price_per_1m: 0.6
        pricing_tier: "budget"
        capabilities:
          - "chat"
          - "vision"
          - "code"
          - "function_calling"
        status: "available"
        context_window: 128000
        training_cutoff: "2023-10"
        supports_vision: true
        supports_tool_use: true
        recommended_for:
          - "fast"
          - "cost-effective"
          - "simple"
        aliases:
          - "gpt4o-mini"

      - id: "o1-preview"
        provider: "openai"
        name: "o1 Preview"
        description: "Reasoning model trained to solve complex problems"
        max_tokens: 32768
        input_price_per_1m: 15.0
        output_price_per_1m: 60.0
        pricing_tier: "premium"
        capabilities:
          - "chat"
          - "reasoning"
          - "code"
        status: "preview"
        context_window: 128000
        training_cutoff: "2023-10"
        supports_vision: true
        supports_tool_use: false
        recommended_for:
          - "reasoning"
          - "complex"
          - "math"
          - "science"

      - id: "text-embedding-3-large"
        provider: "openai"
        name: "Text Embedding 3 Large"
        description: "Most capable embedding model"
        max_tokens: 8191
        input_price_per_1m: 0.13
        output_price_per_1m: 0.0
        pricing_tier: "standard"
        capabilities:
          - "embedding"
        status: "available"
        context_window: 8191
        supports_vision: false
        supports_tool_use: false

  - provider:
      name: "groq"
      base_url: "https://api.groq.com/openai/v1"
      auth_method: "bearer"
      models_endpoint: "/models"
      supports_list: true
      requires_auth: true
      rate_limit_rps: 30
    
    models:
      - id: "llama-3.3-70b-versatile"
        provider: "groq"
        name: "Llama 3.3 70B Versatile"
        description: "Meta's Llama 3.3 70B model on Groq"
        max_tokens: 32768
        input_price_per_1m: 0.59
        output_price_per_1m: 0.79
        pricing_tier: "standard"
        capabilities:
          - "chat"
          - "code"
          - "function_calling"
        status: "available"
        context_window: 128000
        supports_vision: false
        supports_tool_use: true
        recommended_for:
          - "general"
          - "coding"
          - "fast"
        aliases:
          - "llama3.3-70b"

      - id: "llama-3.1-8b-instant"
        provider: "groq"
        name: "Llama 3.1 8B Instant"
        description: "Fast, efficient small model"
        max_tokens: 8192
        input_price_per_1m: 0.05
        output_price_per_1m: 0.08
        pricing_tier: "budget"
        capabilities:
          - "chat"
          - "code"
        status: "available"
        context_window: 128000
        supports_vision: false
        supports_tool_use: false
        recommended_for:
          - "fast"
          - "simple"
          - "chat"
        aliases:
          - "llama3.1-8b"

      - id: "mixtral-8x7b-32768"
        provider: "groq"
        name: "Mixtral 8x7B"
        description: "Mixture of Experts model"
        max_tokens: 32768
        input_price_per_1m: 0.24
        output_price_per_1m: 0.24
        pricing_tier: "standard"
        capabilities:
          - "chat"
          - "code"
        status: "available"
        context_window: 32768
        supports_vision: false
        supports_tool_use: false
        recommended_for:
          - "long-context"
          - "coding"

  - provider:
      name: "openrouter"
      base_url: "https://openrouter.ai/api/v1"
      auth_method: "bearer"
      models_endpoint: "/models"
      supports_list: true
      requires_auth: true
      rate_limit_rps: 20
    
    models:
      - id: "anthropic/claude-3.5-sonnet"
        provider: "openrouter"
        name: "Claude 3.5 Sonnet (via OpenRouter)"
        description: "Claude 3.5 Sonnet through OpenRouter"
        max_tokens: 8192
        input_price_per_1m: 3.0
        output_price_per_1m: 15.0
        pricing_tier: "standard"
        capabilities:
          - "chat"
          - "vision"
          - "code"
        status: "available"
        context_window: 200000
        supports_vision: true
        supports_tool_use: true
        aliases:
          - "claude-sonnet-or"

      - id: "openai/gpt-4o"
        provider: "openrouter"
        name: "GPT-4o (via OpenRouter)"
        description: "GPT-4o through OpenRouter"
        max_tokens: 4096
        input_price_per_1m: 5.0
        output_price_per_1m: 15.0
        pricing_tier: "standard"
        capabilities:
          - "chat"
          - "vision"
          - "code"
        status: "available"
        context_window: 128000
        supports_vision: true
        supports_tool_use: true
        aliases:
          - "gpt-4o-or"

      - id: "mistralai/mixtral-8x22b-instruct"
        provider: "openrouter"
        name: "Mixtral 8x22B"
        description: "Mixtral 8x22B through OpenRouter"
        max_tokens: 65536
        input_price_per_1m: 0.65
        output_price_per_1m: 0.65
        pricing_tier: "standard"
        capabilities:
          - "chat"
          - "code"
        status: "available"
        context_window: 65536
        supports_vision: false
        supports_tool_use: false
        recommended_for:
          - "long-context"
          - "coding"
        aliases:
          - "mixtral-8x22b-or"

      - id: "deepseek/deepseek-chat"
        provider: "openrouter"
        name: "DeepSeek Chat"
        description: "DeepSeek's general purpose chat model"
        max_tokens: 4096
        input_price_per_1m: 0.14
        output_price_per_1m: 0.28
        pricing_tier: "budget"
        capabilities:
          - "chat"
          - "code"
        status: "available"
        context_window: 32768
        supports_vision: false
        supports_tool_use: false

  - provider:
      name: "ollama"
      base_url: "http://localhost:11434/v1"
      auth_method: "none"
      models_endpoint: "/models"
      supports_list: true
      requires_auth: false
      rate_limit_rps: 0
    
    models:
      - id: "llama3.2"
        provider: "ollama"
        name: "Llama 3.2"
        description: "Meta's Llama 3.2 (1B/3B variants)"
        max_tokens: 8192
        input_price_per_1m: 0.0
        output_price_per_1m: 0.0
        pricing_tier: "free"
        capabilities:
          - "chat"
        status: "available"
        context_window: 8192
        supports_vision: false
        supports_tool_use: false
        recommended_for:
          - "local"
          - "fast"
          - "simple"
        aliases:
          - "llama3.2:latest"

      - id: "llama3.1"
        provider: "ollama"
        name: "Llama 3.1"
        description: "Meta's Llama 3.1 (8B/70B/405B variants)"
        max_tokens: 8192
        input_price_per_1m: 0.0
        output_price_per_1m: 0.0
        pricing_tier: "free"
        capabilities:
          - "chat"
          - "code"
        status: "available"
        context_window: 128000
        supports_vision: false
        supports_tool_use: false
        recommended_for:
          - "local"
          - "coding"
          - "powerful"
        aliases:
          - "llama3.1:latest"

      - id: "codellama"
        provider: "ollama"
        name: "CodeLlama"
        description: "Meta's CodeLlama for coding tasks"
        max_tokens: 4096
        input_price_per_1m: 0.0
        output_price_per_1m: 0.0
        pricing_tier: "free"
        capabilities:
          - "chat"
          - "code"
        status: "available"
        context_window: 4096
        supports_vision: false
        supports_tool_use: false
        recommended_for:
          - "local"
          - "coding"
        aliases:
          - "codellama:latest"

      - id: "mistral"
        provider: "ollama"
        name: "Mistral"
        description: "Mistral 7B model"
        max_tokens: 8192
        input_price_per_1m: 0.0
        output_price_per_1m: 0.0
        pricing_tier: "free"
        capabilities:
          - "chat"
          - "code"
        status: "available"
        context_window: 8192
        supports_vision: false
        supports_tool_use: false
        recommended_for:
          - "local"
          - "coding"
        aliases:
          - "mistral:latest"
