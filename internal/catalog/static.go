package catalog

var StaticModels = map[string][]Model{
	"anthropic": {
		{
			ID:              "claude-3-5-sonnet-20241022",
			Provider:        "anthropic",
			Name:            "Claude 3.5 Sonnet",
			Description:     "Balanced intelligence and speed with strong reasoning",
			MaxTokens:       8192,
			ContextWindow:   200000,
			InputPrice:      3.0,
			OutputPrice:     15.0,
			PricingTier:     PricingStandard,
			Capabilities:    []Capability{CapabilityChat, CapabilityVision, CapabilityCode, CapabilityReasoning},
			Status:          ModelStatusAvailable,
			SupportsVision:  true,
			SupportsToolUse: true,
			TrainingCutoff:  "2024-04",
			RecommendedFor:  []string{"coding", "analysis", "reasoning", "general"},
			Aliases:         []string{"claude-sonnet", "sonnet"},
		},
		{
			ID:              "claude-3-5-haiku-20241022",
			Provider:        "anthropic",
			Name:            "Claude 3.5 Haiku",
			Description:     "Fast and cost-effective for lightweight actions",
			MaxTokens:       4096,
			ContextWindow:   200000,
			InputPrice:      1.0,
			OutputPrice:     5.0,
			PricingTier:     PricingBudget,
			Capabilities:    []Capability{CapabilityChat, CapabilityVision},
			Status:          ModelStatusAvailable,
			SupportsVision:  true,
			SupportsToolUse: true,
			TrainingCutoff:  "2024-07",
			RecommendedFor:  []string{"quick", "chat", "simple"},
			Aliases:         []string{"claude-haiku", "haiku"},
		},
		{
			ID:              "claude-3-opus-20240229",
			Provider:        "anthropic",
			Name:            "Claude 3 Opus",
			Description:     "Most capable model for complex tasks",
			MaxTokens:       4096,
			ContextWindow:   200000,
			InputPrice:      15.0,
			OutputPrice:     75.0,
			PricingTier:     PricingPremium,
			Capabilities:    []Capability{CapabilityChat, CapabilityVision, CapabilityCode, CapabilityReasoning},
			Status:          ModelStatusAvailable,
			SupportsVision:  true,
			SupportsToolUse: true,
			TrainingCutoff:  "2024-02",
			RecommendedFor:  []string{"complex", "analysis", "coding", "research"},
			Aliases:         []string{"claude-opus", "opus"},
		},
		{
			ID:             "claude-3-sonnet-20240229",
			Provider:       "anthropic",
			Name:           "Claude 3 Sonnet (Legacy)",
			Description:    "Previous generation Claude 3 Sonnet",
			MaxTokens:      4096,
			ContextWindow:  200000,
			InputPrice:     3.0,
			OutputPrice:    15.0,
			PricingTier:    PricingStandard,
			Capabilities:   []Capability{CapabilityChat, CapabilityVision},
			Status:         ModelStatusLegacy,
			SupportsVision: true,
		},
	},
	"openai": {
		{
			ID:              "gpt-4o",
			Provider:        "openai",
			Name:            "GPT-4o",
			Description:     "Most capable multimodal model, flagship GPT-4 model",
			MaxTokens:       4096,
			ContextWindow:   128000,
			InputPrice:      2.5,
			OutputPrice:     10.0,
			PricingTier:     PricingStandard,
			Capabilities:    []Capability{CapabilityChat, CapabilityVision, CapabilityCode, CapabilityFunctionCall},
			Status:          ModelStatusAvailable,
			SupportsVision:  true,
			SupportsToolUse: true,
			TrainingCutoff:  "2023-10",
			RecommendedFor:  []string{"general", "vision", "multimodal"},
			Aliases:         []string{"gpt4o"},
		},
		{
			ID:              "gpt-4o-mini",
			Provider:        "openai",
			Name:            "GPT-4o Mini",
			Description:     "Affordable and intelligent small model for fast tasks",
			MaxTokens:       16384,
			ContextWindow:   128000,
			InputPrice:      0.15,
			OutputPrice:     0.6,
			PricingTier:     PricingBudget,
			Capabilities:    []Capability{CapabilityChat, CapabilityVision, CapabilityCode, CapabilityFunctionCall},
			Status:          ModelStatusAvailable,
			SupportsVision:  true,
			SupportsToolUse: true,
			TrainingCutoff:  "2023-10",
			RecommendedFor:  []string{"fast", "cost-effective", "simple"},
			Aliases:         []string{"gpt4o-mini"},
		},
		{
			ID:              "o1-preview",
			Provider:        "openai",
			Name:            "o1 Preview",
			Description:     "Reasoning model trained to solve complex problems",
			MaxTokens:       32768,
			ContextWindow:   128000,
			InputPrice:      15.0,
			OutputPrice:     60.0,
			PricingTier:     PricingPremium,
			Capabilities:    []Capability{CapabilityChat, CapabilityReasoning, CapabilityCode},
			Status:          ModelStatusPreview,
			SupportsVision:  true,
			SupportsToolUse: false,
			TrainingCutoff:  "2023-10",
			RecommendedFor:  []string{"reasoning", "complex", "math", "science"},
		},
		{
			ID:              "o1-mini",
			Provider:        "openai",
			Name:            "o1 Mini",
			Description:     "Faster and cheaper reasoning model",
			MaxTokens:       65536,
			ContextWindow:   128000,
			InputPrice:      3.0,
			OutputPrice:     12.0,
			PricingTier:     PricingStandard,
			Capabilities:    []Capability{CapabilityChat, CapabilityReasoning, CapabilityCode},
			Status:          ModelStatusPreview,
			SupportsVision:  true,
			SupportsToolUse: false,
			TrainingCutoff:  "2023-10",
			RecommendedFor:  []string{"reasoning", "coding", "fast"},
		},
		{
			ID:              "gpt-4-turbo",
			Provider:        "openai",
			Name:            "GPT-4 Turbo",
			Description:     "Previous generation with 128K context",
			MaxTokens:       4096,
			ContextWindow:   128000,
			InputPrice:      10.0,
			OutputPrice:     30.0,
			PricingTier:     PricingStandard,
			Capabilities:    []Capability{CapabilityChat, CapabilityVision, CapabilityFunctionCall},
			Status:          ModelStatusLegacy,
			SupportsVision:  true,
			SupportsToolUse: true,
			TrainingCutoff:  "2023-12",
			Aliases:         []string{"gpt-4-turbo-preview"},
		},
		{
			ID:              "text-embedding-3-large",
			Provider:        "openai",
			Name:            "Text Embedding 3 Large",
			Description:     "Most capable embedding model",
			MaxTokens:       8191,
			ContextWindow:   8191,
			InputPrice:      0.13,
			OutputPrice:     0.0,
			PricingTier:     PricingStandard,
			Capabilities:    []Capability{CapabilityEmbedding},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: false,
		},
		{
			ID:              "text-embedding-3-small",
			Provider:        "openai",
			Name:            "Text Embedding 3 Small",
			Description:     "Fast and cost-effective embedding model",
			MaxTokens:       8191,
			ContextWindow:   8191,
			InputPrice:      0.02,
			OutputPrice:     0.0,
			PricingTier:     PricingBudget,
			Capabilities:    []Capability{CapabilityEmbedding},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: false,
		},
	},
	"groq": {
		{
			ID:              "llama-3.3-70b-versatile",
			Provider:        "groq",
			Name:            "Llama 3.3 70B Versatile",
			Description:     "Meta's Llama 3.3 70B model on Groq",
			MaxTokens:       32768,
			ContextWindow:   128000,
			InputPrice:      0.59,
			OutputPrice:     0.79,
			PricingTier:     PricingStandard,
			Capabilities:    []Capability{CapabilityChat, CapabilityCode, CapabilityFunctionCall},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: true,
			RecommendedFor:  []string{"general", "coding", "fast"},
			Aliases:         []string{"llama3.3-70b"},
		},
		{
			ID:              "llama-3.1-8b-instant",
			Provider:        "groq",
			Name:            "Llama 3.1 8B Instant",
			Description:     "Fast, efficient small model",
			MaxTokens:       8192,
			ContextWindow:   128000,
			InputPrice:      0.05,
			OutputPrice:     0.08,
			PricingTier:     PricingBudget,
			Capabilities:    []Capability{CapabilityChat, CapabilityCode},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: false,
			RecommendedFor:  []string{"fast", "simple", "chat"},
			Aliases:         []string{"llama3.1-8b"},
		},
		{
			ID:              "llama3-70b-8192",
			Provider:        "groq",
			Name:            "Llama 3 70B",
			Description:     "Meta's Llama 3 70B on Groq",
			MaxTokens:       8192,
			ContextWindow:   8192,
			InputPrice:      0.59,
			OutputPrice:     0.79,
			PricingTier:     PricingStandard,
			Capabilities:    []Capability{CapabilityChat, CapabilityCode},
			Status:          ModelStatusLegacy,
			SupportsVision:  false,
			SupportsToolUse: false,
			Aliases:         []string{"llama3-70b"},
		},
		{
			ID:              "mixtral-8x7b-32768",
			Provider:        "groq",
			Name:            "Mixtral 8x7B",
			Description:     "Mixture of Experts model",
			MaxTokens:       32768,
			ContextWindow:   32768,
			InputPrice:      0.24,
			OutputPrice:     0.24,
			PricingTier:     PricingStandard,
			Capabilities:    []Capability{CapabilityChat, CapabilityCode},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: false,
			RecommendedFor:  []string{"long-context", "coding"},
		},
		{
			ID:              "gemma-7b-it",
			Provider:        "groq",
			Name:            "Gemma 7B",
			Description:     "Google's Gemma 7B on Groq",
			MaxTokens:       8192,
			ContextWindow:   8192,
			InputPrice:      0.07,
			OutputPrice:     0.07,
			PricingTier:     PricingBudget,
			Capabilities:    []Capability{CapabilityChat},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: false,
			RecommendedFor:  []string{"fast", "simple"},
		},
	},
	"opencode": {
		{
			ID:              "zed",
			Provider:        "opencode",
			Name:            "OpenCode Zed",
			Description:     "High-performance coding model",
			MaxTokens:       8192,
			ContextWindow:   128000,
			InputPrice:      0.0,
			OutputPrice:     0.0,
			PricingTier:     PricingStandard,
			Capabilities:    []Capability{CapabilityChat, CapabilityCode, CapabilityReasoning},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: true,
			RecommendedFor:  []string{"coding", "development"},
		},
	},
	"ollama": {
		{
			ID:              "llama3.2",
			Provider:        "ollama",
			Name:            "Llama 3.2",
			Description:     "Meta's Llama 3.2 (1B/3B variants)",
			MaxTokens:       8192,
			ContextWindow:   8192,
			InputPrice:      0.0,
			OutputPrice:     0.0,
			PricingTier:     PricingFree,
			Capabilities:    []Capability{CapabilityChat},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: false,
			RecommendedFor:  []string{"local", "fast", "simple"},
			Aliases:         []string{"llama3.2:latest"},
		},
		{
			ID:              "llama3.1",
			Provider:        "ollama",
			Name:            "Llama 3.1",
			Description:     "Meta's Llama 3.1 (8B/70B/405B variants)",
			MaxTokens:       8192,
			ContextWindow:   128000,
			InputPrice:      0.0,
			OutputPrice:     0.0,
			PricingTier:     PricingFree,
			Capabilities:    []Capability{CapabilityChat, CapabilityCode},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: false,
			RecommendedFor:  []string{"local", "coding", "powerful"},
			Aliases:         []string{"llama3.1:latest"},
		},
		{
			ID:              "mistral",
			Provider:        "ollama",
			Name:            "Mistral",
			Description:     "Mistral 7B model",
			MaxTokens:       8192,
			ContextWindow:   8192,
			InputPrice:      0.0,
			OutputPrice:     0.0,
			PricingTier:     PricingFree,
			Capabilities:    []Capability{CapabilityChat, CapabilityCode},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: false,
			RecommendedFor:  []string{"local", "coding"},
			Aliases:         []string{"mistral:latest"},
		},
		{
			ID:              "qwen2.5",
			Provider:        "ollama",
			Name:            "Qwen 2.5",
			Description:     "Alibaba's Qwen 2.5 model",
			MaxTokens:       32768,
			ContextWindow:   32768,
			InputPrice:      0.0,
			OutputPrice:     0.0,
			PricingTier:     PricingFree,
			Capabilities:    []Capability{CapabilityChat, CapabilityCode},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: false,
			RecommendedFor:  []string{"local", "long-context", "coding"},
			Aliases:         []string{"qwen2.5:latest"},
		},
		{
			ID:              "codellama",
			Provider:        "ollama",
			Name:            "CodeLlama",
			Description:     "Meta's CodeLlama for coding tasks",
			MaxTokens:       4096,
			ContextWindow:   4096,
			InputPrice:      0.0,
			OutputPrice:     0.0,
			PricingTier:     PricingFree,
			Capabilities:    []Capability{CapabilityChat, CapabilityCode},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: false,
			RecommendedFor:  []string{"local", "coding"},
			Aliases:         []string{"codellama:latest"},
		},
		{
			ID:              "gemma2",
			Provider:        "ollama",
			Name:            "Gemma 2",
			Description:     "Google's Gemma 2 model",
			MaxTokens:       8192,
			ContextWindow:   8192,
			InputPrice:      0.0,
			OutputPrice:     0.0,
			PricingTier:     PricingFree,
			Capabilities:    []Capability{CapabilityChat},
			Status:          ModelStatusAvailable,
			SupportsVision:  false,
			SupportsToolUse: false,
			RecommendedFor:  []string{"local", "fast"},
			Aliases:         []string{"gemma2:latest"},
		},
	},
}

func GetStaticModels(provider string) []Model {
	if models, ok := StaticModels[provider]; ok {
		return models
	}
	return nil
}

var ProviderConfigs = map[string]ProviderConfig{
	"anthropic": {
		Name:           "anthropic",
		BaseURL:        "https://api.anthropic.com/v1",
		AuthMethod:     AuthMethodAPIKey,
		ModelsEndpoint: "/models",
		SupportsList:   false,
		RequiresAuth:   true,
		RateLimitRPS:   50,
		DefaultHeaders: map[string]string{
			"anthropic-version": "2023-06-01",
		},
	},
	"openai": {
		Name:           "openai",
		BaseURL:        "https://api.openai.com/v1",
		AuthMethod:     AuthMethodBearer,
		ModelsEndpoint: "/models",
		SupportsList:   true,
		RequiresAuth:   true,
		RateLimitRPS:   100,
	},
	"groq": {
		Name:           "groq",
		BaseURL:        "https://api.groq.com/openai/v1",
		AuthMethod:     AuthMethodBearer,
		ModelsEndpoint: "/models",
		SupportsList:   true,
		RequiresAuth:   true,
		RateLimitRPS:   30,
	},
	"opencode": {
		Name:           "opencode",
		BaseURL:        "https://api.opencode.com/v1",
		AuthMethod:     AuthMethodAPIKey,
		ModelsEndpoint: "/models",
		SupportsList:   false,
		RequiresAuth:   true,
		RateLimitRPS:   10,
	},
	"ollama": {
		Name:           "ollama",
		BaseURL:        "http://localhost:11434/v1",
		AuthMethod:     AuthMethodNone,
		ModelsEndpoint: "/models",
		SupportsList:   true,
		RequiresAuth:   false,
		RateLimitRPS:   0,
	},
}

func GetProviderConfig(name string) (ProviderConfig, bool) {
	config, ok := ProviderConfigs[name]
	return config, ok
}

func GetAllProviderConfigs() []ProviderConfig {
	configs := make([]ProviderConfig, 0, len(ProviderConfigs))
	for _, config := range ProviderConfigs {
		configs = append(configs, config)
	}
	return configs
}